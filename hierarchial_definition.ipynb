{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b26c03fb-b509-4b33-98f0-31b3df65fa21",
   "metadata": {},
   "source": [
    "<h3 style='color:green;'>Hierarchical Clustering.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dc105d-a9a8-4678-8562-1b86ed121192",
   "metadata": {},
   "source": [
    "Clustering is the process of dividing datasets into groups, consisting of similar data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bd3374-9e8f-426b-81aa-e49b1cff0ab7",
   "metadata": {},
   "source": [
    "Hierarchical Clustering also known as HCA is a method of cluster analysis that allows to build tree structure from data similarities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a7ef4a-663a-461d-aa84-be70adb53008",
   "metadata": {},
   "source": [
    "<h3 style='color:black;'>Types of Hierarchical clustering.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba637764-6621-40a5-8fcf-2798615edb7e",
   "metadata": {},
   "source": [
    "<h3 style='color:black;'>1. Agglomerative Clustering</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca6a358-ea95-42fa-a892-89d6bfe75e0e",
   "metadata": {},
   "source": [
    "It is also known as AGNES(Agglomerative Nesting Hierarchical Clustering.)\n",
    "\n",
    "It is a bottom up approach\n",
    "\n",
    "Clustering continues until a single cluster is obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413dbd1f-6651-4a2e-af34-f91f141f65d7",
   "metadata": {},
   "source": [
    "<h3 style='color:black;'>2. Divisive Clustering.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7fa5e3-cde1-4159-9e22-b5b016b4f609",
   "metadata": {},
   "source": [
    "It is also as DIANA(Divisive Analysis Clustering Algorithm).\n",
    "                    \n",
    "It is a Top-Bottom approach.\n",
    "\n",
    "Clustering cntinues until small groups of similar clusters are obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f3b21c-9f49-4d67-b93e-1a948604607e",
   "metadata": {},
   "source": [
    "<h3 style='color:black;'>Key Concepts:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d539d3ae-00da-4301-b3f0-1cb78b076f80",
   "metadata": {},
   "source": [
    "<h3 style='color:black;'>Dendrogram:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5550b28b-36ab-4e3f-94f1-de9aa1593a6e",
   "metadata": {},
   "source": [
    "A tree-like diagram that represents the hierarchical clustering process, showing the merging or splitting of clusters at different distances. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cb567f-1a21-446d-97c3-1bf09244e3f1",
   "metadata": {},
   "source": [
    "<h3 style='color:black;'>Distance Metric:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707b5c61-fb2b-464e-b966-3e49f9224c20",
   "metadata": {},
   "source": [
    "Used to determine the similarity or dissimilarity between data points or clusters (e.g., Euclidean distance, Manhattan distance). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f4732-e55d-451f-9190-2285d2cc8fbe",
   "metadata": {},
   "source": [
    "<h3 style='color:black;'>Linkage Criteria:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5308d8fe-0c0e-435c-bc75-fc2e12bb7522",
   "metadata": {},
   "source": [
    "Defines how the distance between clusters is calculated (e.g., single linkage, complete linkage, average linkage, Ward's method)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9716d4f7-eb14-491b-9ca5-bc07526cab28",
   "metadata": {},
   "source": [
    "<h3 style='color:black;'>Example:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd8e6dd-99d4-4d40-81d5-d04acf38bedd",
   "metadata": {},
   "source": [
    "Imagine grouping fruits based on their weights. Hierarchical clustering could start by treating each fruit as a separate cluster. Then, it would merge the closest pairs of fruits based on their weight (e.g., a cherry and a grape might be merged first). This process continues until all fruits are grouped into a single cluster. The dendrogram would visually represent these merging steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dff715b-70b5-4504-ab78-721bcf14196f",
   "metadata": {},
   "source": [
    "<h3 style='color:black;'>Advantages of Hierarchial clustering over K-means clustering.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ff5fec-e878-42d2-830f-c2b150e33583",
   "metadata": {},
   "source": [
    "1. Hierarchial Clustering is faster on large datasets.\n",
    "2. Hierachial clustering does not require specifying the number of clusters in advance.\n",
    "3. Hierarchial clustering always produces better cluster results.\n",
    "4. Hierarchial clustering works well with non-numeric data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b70d4ec-a588-463a-80f7-322753379882",
   "metadata": {},
   "source": [
    "<h3 style='color:black;'>How to decide the number of clusters.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583025b3-6da9-40c9-ab40-2b45d0d535c3",
   "metadata": {},
   "source": [
    "-Based on the similarity, single linkage, complete linkage\n",
    "\n",
    "- Similarity is obtained by calculating distance between clusters.\n",
    "\n",
    "- Distance Metrics like Euclidian, manhattan etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63e53e7-a1d1-4887-a240-966d4e8a4f60",
   "metadata": {},
   "source": [
    "<h3 style='color:black;'>Application</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425d6de0-0173-4e49-bee8-7f3a1680b762",
   "metadata": {},
   "source": [
    "1. Used in taxonomy, biological classification of animals or plants kingdom.\n",
    "2. Tracking viral outbreaks.\n",
    "3. clustering Crime sites in the city.\n",
    "4. Segmenting the customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc939f0-d9e8-4bc9-aace-0600f7483d1e",
   "metadata": {},
   "source": [
    "<h3 style='color:black;'>Advantages</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254333be-e05d-4c8e-ba1a-173fb22bd27d",
   "metadata": {},
   "source": [
    "1. Easy to implement and understand.\n",
    "2. No prior information is required about the numbers of clusters.\n",
    "3. Outliers can be detected with the help of a Dendrogram.\n",
    "4. Deterministic, more predictable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9869cfaa-e886-41f0-a13e-2edd428b69f4",
   "metadata": {},
   "source": [
    "<h3 style='color:black;'>Disadvantages.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b84489c-3271-41f8-92d8-13fb61f46cd8",
   "metadata": {},
   "source": [
    "It is not suitable for large datasets.\n",
    "\n",
    "Difficulty in handling different sized clusters.\n",
    "\n",
    "It is sensitive to outliers and noise in the datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
