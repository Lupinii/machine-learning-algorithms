{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "829b8b1f-0319-4c7b-9825-b001eff16387",
   "metadata": {},
   "source": [
    "<h3 style='color:green'>Association Rule Learning.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b6e6e-884b-4ddd-adbd-55eb3afb6cbf",
   "metadata": {},
   "source": [
    "<h3 style='color:black'>Market Basket Analysis</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1bee01-8fd3-4d4c-949b-7c214f7de44a",
   "metadata": {},
   "source": [
    "Market Analysis is one of the key techniques used by large retailers to uncover association between items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cd5674-fc76-46df-b4d3-970b32e08ea8",
   "metadata": {},
   "source": [
    "<h3 style='color:black'>Association Rule Mining</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b500760-5d0c-4746-9cc1-5d276e234fd1",
   "metadata": {},
   "source": [
    "Association rule learning is a kind of unsupervised learning technique that tests for the reliance of one data element on another data element and design appropriately so that it can be more cost-effective.\n",
    "\n",
    "It tries to discover some interesting relations or associations between variables in a dataset.\n",
    "\n",
    "It depends on various rules to find interesting relations between variables.\n",
    "\n",
    "[A]If(antecedent) --> [B]Then(consequent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45383ab-9035-4407-8074-50c17678b8d6",
   "metadata": {},
   "source": [
    "<h3 style='color:black'>Key Concepts</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e72cf8d-f575-43a0-b62c-0e41175974d6",
   "metadata": {},
   "source": [
    "1. **Support**: The frequency of the itemset in the dataset. Support(X) = (Number of transactions containing X) / (Total number of transactions)\n",
    "2. **Confidence**: The likelihood that item Y is purchased when item X is purchased. Confidence(X → Y) = Support(X ∪ Y) / Support(X)\n",
    "3. **Lift**: The ratio of the observed support to that expected if X and Y were independent. Lift(X → Y) = Support(X ∪ Y) / (Support(X) * Support(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef2f761-094b-4d9e-9acf-2a730888975e",
   "metadata": {},
   "source": [
    "<h3 style='color:black'>Algorithms</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d3f8ff-a490-42d8-ad40-159bbeddd9f7",
   "metadata": {},
   "source": [
    "<h3 style='color:green'>1. Apriori</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe2cdeb-84a2-4c6c-a151-6e9380d8a5d5",
   "metadata": {},
   "source": [
    "This Algorithm needs frequent datasets to produce association rules. \n",
    "\n",
    "It is designed to work on databases that include transactions.\n",
    "\n",
    "This Algorithm needs breadth-first search and hash tree to compute the item set efficienty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960be9fb-eb9b-47f9-bd5e-26397dac3200",
   "metadata": {},
   "source": [
    "The Apriori algorithm uses a breadth-first search strategy to count the support of itemsets and uses a \"bottom-up\" approach, where frequent subsets are extended one item at a time (a step known as candidate generation), and groups of candidates are tested against the data. The algorithm terminates when no further successful extensions are found.\n",
    "\n",
    "**Steps:**\n",
    "- **Step 1**: Set a minimum support and confidence.\n",
    "- **Step 2**: Take all itemsets having support higher than the minimum support.\n",
    "- **Step 3**: Generate association rules from these itemsets with confidence greater than the minimum confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010b5e7f-e12d-421c-b8a9-9a8a62cd071d",
   "metadata": {},
   "source": [
    "**Example**:\n",
    "Consider a supermarket transaction data:\n",
    "| Transaction ID | Items                     |\n",
    "|----------------|---------------------------|\n",
    "| 1              | Bread, Butter, Jam       |\n",
    "| 2              | Bread, Butter            |\n",
    "| 3              | Bread, Milk, Butter      |\n",
    "| 4              | Bread, Milk, Jam         |\n",
    "| 5              | Milk, Jam                |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98318983-85a9-4289-a479-00587e3362cb",
   "metadata": {},
   "source": [
    "**Step 1**: Find frequent itemsets (with min support = 0.4, i.e., at least 2 transactions)\n",
    "\n",
    "**First pass (itemsets of size 1):**\n",
    "- Items: Bread, Butter, Jam, Milk\n",
    "  \n",
    "- Support:\n",
    "    - Bread: 4/5 = 0.8\n",
    "    - Butter: 3/5 = 0.6\n",
    "    - Jam: 3/5 = 0.6\n",
    "    - Milk: 3/5 = 0.6\n",
    "All are above min support (0.4).\n",
    "\n",
    "**Second pass (itemsets of size 2):**\n",
    "Candidate itemsets: {Bread, Butter}, {Bread, Jam}, {Bread, Milk}, {Butter, Jam}, {Butter, Milk}, {Jam, Milk}\n",
    "\n",
    "- Support:\n",
    "    - {Bread, Butter}: 3/5 = 0.6\n",
    "    - {Bread, Jam}: 2/5 = 0.4\n",
    "    - {Bread, Milk}: 2/5 = 0.4\n",
    "    - {Butter, Jam}: 1/5 = 0.2 -> below, discard\n",
    "    - {Butter, Milk}: 1/5 = 0.2 -> discard\n",
    "    - {Jam, Milk}: 2/5 = 0.4\n",
    "      \n",
    "Frequent 2-itemsets: {Bread, Butter}, {Bread, Jam}, {Bread, Milk}, {Jam, Milk}\n",
    "\n",
    "**Third pass (itemsets of size 3):**\n",
    "Candidate from 2-itemsets: {Bread, Jam, Milk} (since {Bread, Jam}, {Bread, Milk}, {Jam, Milk} are frequent)\n",
    "\n",
    "- Support for {Bread, Jam, Milk}: 1/5 = 0.2 -> below, discard.\n",
    "  \n",
    "So, the frequent itemsets are all 1-itemsets and the 2-itemsets we found.\n",
    "\n",
    "**Step 2**: Generate association rules from frequent itemsets (min confidence = 0.5)\n",
    "\n",
    "For itemset {Bread, Butter}:\n",
    "- Bread → Butter: Confidence = Support({Bread,Butter}) / Support(Bread) = 0.6 / 0.8 = 0.75 (>=0.5) -> rule accepted.\n",
    "- Butter → Bread: Confidence = 0.6 / 0.6 = 1.0 -> rule accepted.\n",
    "  \n",
    "For itemset {Bread, Jam}:\n",
    "- Bread → Jam: Confidence = 0.4 / 0.8 = 0.5 -> rule accepted.\n",
    "- Jam → Bread: Confidence = 0.4 / 0.6 ≈ 0.67 -> rule accepted.\n",
    "  \n",
    "For itemset {Bread, Milk}:\n",
    "- Bread → Milk: Confidence = 0.4 / 0.8 = 0.5 -> rule accepted.\n",
    "- Milk → Bread: Confidence = 0.4 / 0.6 ≈ 0.67 -> rule accepted.\n",
    "  \n",
    "For itemset {Jam, Milk}:\n",
    "- Jam → Milk: Confidence = Support({Jam, Milk}) / Support(Jam) = 0.4 / 0.6 ≈ 0.67 -> rule accepted.\n",
    "- Milk → Jam: Confidence = 0.4 / 0.6 ≈ 0.67 -> rule accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb32e676-85ac-43ed-8a9f-8517f6adcbda",
   "metadata": {},
   "source": [
    "<h3 style='color:green'>2. Eclat</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af96a90-91ac-485f-b2c7-1490671bbb4e",
   "metadata": {},
   "source": [
    "The Eclat algorithm represents Equivalence Class Transformation. \n",
    "\n",
    "This algorithm needs a depth-first search method to discover frequent itemsets in a transaction database. \n",
    "\n",
    "It implements quicker execution than the Apriori Algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e163aa3-ddfd-4ae9-b642-8c9c8a01f562",
   "metadata": {},
   "source": [
    "Eclat (Equivalence Class Clustering and bottom-up Lattice Traversal) is a depth-first search algorithm using set intersection. It uses a vertical database layout (i.e., for each item, it records the set of transactions that contain it). The support of an itemset is the size of the intersection of the transaction sets of the items in the itemset.\n",
    "\n",
    "**Steps**:\n",
    "\n",
    "- **Step 1**: Convert the database into a vertical format.\n",
    "- \n",
    "- **Step 2**: The support of an itemset is the length of the intersection of the tids (transaction IDs) of the items.\n",
    "- \n",
    "- **Step 3**: Generate frequent itemsets by intersecting tidsets of items, starting with single items and then growing by one item at a time (depth-first).\n",
    "  \n",
    "**Example**:\n",
    "Same transaction data:\n",
    "Vertical format:\n",
    "- Bread: {1,2,3,4}\n",
    "- Butter: {1,2,3}\n",
    "- Jam: {1,4,5}\n",
    "- Milk: {3,4,5}\n",
    "  \n",
    "**Step 1**: Find frequent 1-itemsets (min support=2, so at least 2 transactions). All are frequent.\n",
    "  \n",
    "**Step 2**: For 2-itemsets, we intersect the tids of every pair of items.\n",
    "- Bread ∩ Butter = {1,2,3} (size=3) -> support=3\n",
    "- Bread ∩ Jam = {1,4} (size=2) -> support=2\n",
    "- Bread ∩ Milk = {3,4} (size=2) -> support=2\n",
    "- Butter ∩ Jam = {1} (size=1) -> support=1 -> discard\n",
    "- Butter ∩ Milk = {3} (size=1) -> discard\n",
    "- Jam ∩ Milk = {4,5} (size=2) -> support=2\n",
    "- \n",
    "Frequent 2-itemsets: {Bread, Butter}, {Bread, Jam}, {Bread, Milk}, {Jam, Milk}\n",
    "\n",
    "**Step 3**: For 3-itemsets, we combine 2-itemsets that share a common prefix (in depth-first manner, but we can do systematically).\n",
    "\n",
    "For example, from {Bread, Jam} and {Bread, Milk}, we get candidate {Bread, Jam, Milk} by intersecting the tids of Jam and Milk? Actually, we can do:\n",
    "\n",
    "We can combine itemsets that have a common prefix (in a DFS fashion). But note: to form a 3-itemset, we take two 2-itemsets that share the same first item (if we sort the items) and then intersect their tids.\n",
    "\n",
    "Candidate: {Bread, Jam, Milk} = (Bread ∩ Jam) ∩ (Bread ∩ Milk) ? Actually, we can compute the tidset as the intersection of the tids of all three: Bread ∩ Jam ∩ Milk = {1,2,3,4} ∩ {1,4,5} ∩ {3,4,5} = {4} (only transaction 4) -> support=1 -> discard.\n",
    "\n",
    "So, we stop at 2-itemsets.\n",
    "\n",
    "Generating rules is similar to Apriori."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423dfca6-b69f-4835-8581-2be99e5e6328",
   "metadata": {},
   "source": [
    "<h3 style='color:green'>F-P Growth</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d773404-2279-43cc-8b38-31e6b3196bfc",
   "metadata": {},
   "source": [
    "The F-P growth algorithm represents Frequent pattern. \n",
    "\n",
    "It is the enhanced version of the Apriori Algorithm.\n",
    "\n",
    "It describes the database in the form of a tree structure that is reffered as to as a frequent pattern or tree.\n",
    "\n",
    "This frequent tree aims to extract the most frequent patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd074b6a-7805-482b-80a1-f0e63e628357",
   "metadata": {},
   "source": [
    "<h3 style='color:black'>Use Case:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c5f5c5-bb58-4137-82ff-7348d66ff09c",
   "metadata": {},
   "source": [
    "- Apriori: Small datasets with low minsup.\n",
    "\n",
    "- Eclat: Medium datasets with moderate items.\n",
    "\n",
    "- FP-Growth: Large-scale datasets (e.g., retail transaction data)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
